# Set environment variables in the format KEY=VALUE, 1 per line
# This file will be sourced inside the project container when started.
# NOTE: If you change this file while the project is running, you must restart the project container for changes to take effect.

MODEL_DIRECTORY=/tmp
DOCKER_VOLUME_DIRECTORY=database
NVWB_FLAG=true

# ==== Endpoints for using on-prem NIMs ====
APP_LLM_SERVERURL=nemollm-inference:8000
APP_LLM_MODELNAME=meta/llama-3.1-70b-instruct
APP_EMBEDDINGS_SERVERURL=nemollm-embedding:8000
APP_RANKING_SERVERURL=ranking-ms:8000

# ==== OPTIONAL GPU Assignments ====
# LLM_MS_GPU_ID_1: Update this to specify the LLM GPU IDs (e.g., 0).
# LLM_MS_GPU_ID_2: Update this to specify the LLM GPU IDs (e.g., 1).
# LLM_MS_GPU_ID_3: Update this to specify the LLM GPU IDs (e.g., 2).
# LLM_MS_GPU_ID_4: Update this to specify the LLM GPU IDs (e.g., 3).
# EMBEDDING_MS_GPU_ID: Change this to set the embedding GPU ID (e.g., 4).
# RANKING_MS_GPU_ID: Modify this to adjust the reranking LLM GPU ID (e.g., 5).
# VECTORSTORE_GPU_DEVICE_ID : Modify to adjust the Milvus vector database GPU ID (e.g., 0).